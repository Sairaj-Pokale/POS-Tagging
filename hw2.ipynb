{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('data/train.json') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "train_labels= []\n",
    "for i in range(len(train_data)):\n",
    "    for j in train_data[i]['sentence']:\n",
    "        train_sentences.append(j)\n",
    "\n",
    "for k in range(len(train_data)):\n",
    "    for l in train_data[k]['labels']:\n",
    "        train_labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912095\n",
      "912095\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for i in range(len(train_sentences)):\n",
    "    if train_sentences[i] in vocab:\n",
    "        vocab[train_sentences[i]] += 1\n",
    "    else:\n",
    "        vocab[train_sentences[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_vocab = {}\n",
    "num_unk = 0\n",
    "\n",
    "for w in vocab:\n",
    "    if vocab[w] >= 3:\n",
    "        known_vocab[w] = vocab[w]\n",
    "    else:\n",
    "        num_unk += vocab[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sorted = sorted(vocab.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1943685"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43193 * 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('output/vocab.txt', 'w') as vocab_file:\n",
    "    vocab_file.write('<unk>' + '\\t' + str(0) + '\\t' + str(num_unk) + '\\n')\n",
    "    for i in range(len(vocab_sorted)):\n",
    "        vocab_file.write(str(vocab_sorted[i][0]) + '\\t' + str(i+1) + '\\t' + str(vocab_sorted[i][1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab :  43193\n",
      "\n",
      "Total occurrences of <unk> is :  32537\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocab : ',len(vocab_sorted))\n",
    "print('\\nTotal occurrences of <unk> is : ',num_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_ls = list(known_vocab.keys())\n",
    "\n",
    "for i in range(len(train_sentences)):\n",
    "    if train_sentences[i] not in vocab_ls:\n",
    "        train_sentences[i] = \"<unk>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_words = list(known_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = {}\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i]['sentence'])):\n",
    "        #print(train_data[i]['sentence'][j])\n",
    "        sent = train_data[i]['sentence']\n",
    "        label = train_data[i]['labels']\n",
    "        if str(sent[j]) + '||' + str(label[j]) in sx:\n",
    "            sx[str(sent[j]) + '||' + str(label[j])] +=1\n",
    "        else:\n",
    "            sx[str(sent[j]) + '||' + str(label[j])] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i]['sentence'])):\n",
    "        sent = train_data[i]['sentence']\n",
    "        label = train_data[i]['labels']\n",
    "        if sent[j]  not in known_words:\n",
    "            tg = \"<unk>\"\n",
    "            if str(tg) + '||' + str(label[j]) in sx:\n",
    "                sx[str(tg) + '||' + str(label[j])] += 1\n",
    "            else:\n",
    "                sx[str(tg) + '||' + str(label[j])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3242"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx['<unk>||NNS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = {}\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i]['labels'])):\n",
    "        label = train_data[i]['labels']\n",
    "        if j+1 < len(train_data[i]['labels']):\n",
    "            if str(label[j+1]) + '||' + str(label[j]) in ss:\n",
    "                ss[str(label[j+1]) + '||' + str(label[j])] += 1\n",
    "            else:\n",
    "                ss[str(label[j+1]) + '||' + str(label[j])] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sxsx = {}\n",
    "# for i in range(len(train_sentences)):\n",
    "#     # print(\"word: \", train_sentences[i])\n",
    "#     # print(\"label: \", train_labels[i])\n",
    "#     # break\n",
    "#     if train_sentences[i] in known_words:\n",
    "#         if str(train_sentences[i]) + '|' + str(train_labels[i]) in sxsx:\n",
    "#             sxsx[str(train_sentences[i]) + '|' + str(train_labels[i])] += 1\n",
    "#         else: \n",
    "#             sxsx[str(train_sentences[i]) + '|' + str(train_labels[i])] = 1\n",
    "#     else:\n",
    "#         s = \"<unk>\"\n",
    "#         if str(s) + '|' + str(train_labels[i]) in sxsx:\n",
    "#             sxsx[str(s) + '|' + str(train_labels[i])] += 1\n",
    "#         else: \n",
    "#             sxsx[str(s) + '|' + str(train_labels[i])] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sxsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = 0\n",
    "# for i in range(len(train_sentences)):\n",
    "#     if (train_sentences[i] not in vocab2.keys()) and (train_labels[i] == 'NNP'):\n",
    "#         check +=1\n",
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count={}\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i]['labels'])):\n",
    "        label = train_data[i]['labels']\n",
    "        if label[j] in pos_count:\n",
    "            pos_count[label[j]] += 1\n",
    "        else:\n",
    "            pos_count[label[j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_pos = list(pos_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87608"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_count['NNP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission = {}\n",
    "transition = {}\n",
    "\n",
    "for i in sx:\n",
    "    emission[i] = sx[i] / pos_count[str(i).split('||')[1]]\n",
    "\n",
    "for j in ss:\n",
    "    transition[j] = ss[j] / pos_count[str(j).split('||')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50320"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38218"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = {}\n",
    "for i in range(len(train_data)):\n",
    "    if train_data[i]['labels'][0] in pr:\n",
    "        pr[train_data[i]['labels'][0]] += 1\n",
    "    else:\n",
    "        pr[train_data[i]['labels'][0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = {}\n",
    "\n",
    "for k in pr.keys():\n",
    "    prior[k] = pr[k]/len(train_data)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = {\"initial: \":prior,\"transition\":transition, \"emission\":emission}\n",
    "json_object = json.dumps(hmm, indent=2)\n",
    "with open('output/hmm.json', 'w') as op:\n",
    "    op.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1539.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.026599146200245425 * pos_count['NNS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3242"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx['<unk>||NNS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['Huricane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist = []\n",
    "\n",
    "def greedy(sentence):\n",
    "    postags = []\n",
    "    sent = sentence[0]\n",
    "    if sent not in known_words:\n",
    "        sent = \"<unk>\"\n",
    "    maxp = 0\n",
    "    p0 = 'UNK'\n",
    "\n",
    "    for p in distinct_pos:\n",
    "        try:\n",
    "            temp = emission[sent + '||' + p] * prior[p]\n",
    "            if temp>maxp:\n",
    "                maxp = temp\n",
    "                p0 = p\n",
    "        except:\n",
    "            pass\n",
    "    postags.append(p0)\n",
    "    \n",
    "\n",
    "    for i in range(1, len(sentence)):\n",
    "        sent = sentence[i]\n",
    "        if sent not in known_words:\n",
    "            sent = \"<unk>\"\n",
    "        max_p = 0\n",
    "        pi = 'UNK'\n",
    "\n",
    "        for p in distinct_pos:\n",
    "            try:\n",
    "                temp = emission[sent + '||' + p] * transition[p + '||' + postags[-1]]\n",
    "                if temp > max_p:\n",
    "                    max_p = temp \n",
    "                    pi = p\n",
    "            except:\n",
    "                pass\n",
    "        postags.append(pi)\n",
    "\n",
    "    mlist.append(postags)\n",
    "    return postags\n",
    "\n",
    "\n",
    "with open('data/dev.json') as data:\n",
    "    dev_data = json.load(data)\n",
    "glist=[]\n",
    "for i in range(len(dev_data)):\n",
    "    glist.append(greedy(dev_data[i]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "\n",
    "for i in range(len(glist)):\n",
    "    for j in glist[i]:\n",
    "        pred_list.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for i in range(len(dev_data)):\n",
    "    for j in range(len(dev_data[i]['labels'])):\n",
    "        target_list.append(dev_data[i]['labels'][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131768"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131768"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122119"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(target_list)):\n",
    "    if target_list[i] == pred_list[i]:\n",
    "        correct+=1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.67728128225366"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(correct/131768)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9267728128225365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(target_list, pred_list)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(vsentence):\n",
    "    s = {i:{} for i in range(len(vsentence))}\n",
    "    initialpos = {i:{} for i in range(len(vsentence))}\n",
    "    sent = vsentence[0]\n",
    "    if sent not in known_words:\n",
    "        sent = \"<unk>\"\n",
    "    \n",
    "    for p in distinct_pos:\n",
    "        if p in prior:\n",
    "            try:\n",
    "                s[0][p] = emission[sent + '||' + p] * prior[p]\n",
    "            except:\n",
    "                s[0][p] =0\n",
    "    for p in s[0].keys():\n",
    "        initialpos[0][p] = 'NNP'\n",
    "\n",
    "    for i in range(1, len(vsentence)):\n",
    "        sent = vsentence[i]\n",
    "        if sent not in known_words:\n",
    "            sent = \"<unk>\"\n",
    "            \n",
    "        for p in s[i-1].keys():\n",
    "            for pos_i in distinct_pos:\n",
    "                if pos_i + '||' + p in transition:\n",
    "                    if pos_i in s[i]:\n",
    "                        try:\n",
    "                            temp = s[i-1][p] * transition[pos_i + '||' + p] * emission[sent + '||' + pos_i]\n",
    "                            if temp > s[i][pos_i]:\n",
    "                                s[i][pos_i] = temp\n",
    "                                initialpos[i][pos_i] = p\n",
    "                        except:\n",
    "                            pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            s[i][pos_i] = s[i-1][p] * transition[pos_i + '||' + p] * emission[sent + '||' + pos_i]\n",
    "                            initialpos[i][pos_i] = p\n",
    "                        except:\n",
    "\n",
    "                            s[i][pos_i] = 0\n",
    "\n",
    "    \n",
    "    s_pred = []\n",
    "\n",
    "    maxp = max(s[len(vsentence)-1].values())\n",
    "\n",
    "    maxp_index = list(s[len(vsentence)-1].values()).index(maxp)\n",
    "\n",
    "    pos_maxp = list(s[len(vsentence)-1].keys())[maxp_index]\n",
    "    s_pred.append(pos_maxp)\n",
    "\n",
    "    for q in range(len(vsentence)-1,0,-1):\n",
    "        try:\n",
    "            pos_maxp = initialpos[q][pos_maxp]\n",
    "            s_pred.append(pos_maxp)\n",
    "        except:\n",
    "            s_pred.append('UNK')\n",
    "    \n",
    "    reversed_s_pred=[]\n",
    "    for i  in range(len(s_pred)-1, -1, -1):\n",
    "        reversed_s_pred.append(s_pred[i])\n",
    "\n",
    "    return reversed_s_pred\n",
    "\n",
    "\n",
    "\n",
    "with open('data/dev.json') as data:\n",
    "    dev_data = json.load(data)\n",
    "\n",
    "v_pred_list = []\n",
    "for i in range(len(dev_data)):\n",
    "    v_pred_list.append(viterbi(dev_data[i]['sentence']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpred = []\n",
    "for i in range(len(v_pred_list)):\n",
    "    for j in v_pred_list[i]:\n",
    "        vpred.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124344\n"
     ]
    }
   ],
   "source": [
    "vcorrect = 0\n",
    "for i in range(len(target_list)):\n",
    "    if target_list[i] == vpred[i]:\n",
    "        vcorrect+=1\n",
    "print(vcorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.36585513933579"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vcorrect/131768)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943658551393358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(target_list, vpred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.json') as data:\n",
    "    test_data = json.load(data)\n",
    "\n",
    "viterbi_pred_list = []\n",
    "for i in range(len(test_data)):\n",
    "    #print(test_data[i]['sentence'])\n",
    "    viterbi_pred_list.append(viterbi(test_data[i]['sentence']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(viterbi_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbil = []\n",
    "\n",
    "\n",
    "for i in range(len(viterbi_pred_list)):\n",
    "    viterbidict = {}\n",
    "    viterbidict[\"index\"] = i\n",
    "    viterbidict[\"sentence\"] = test_data[i]['sentence'] \n",
    "    viterbidict[\"labels\"] = viterbi_pred_list[i]\n",
    "    viterbil.append(viterbidict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(viterbil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbijson = json.dumps(viterbil, indent=2)\n",
    "with open('output/viterbi.json','w') as op:\n",
    "    op.write(viterbijson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.json') as data:\n",
    "    test_data = json.load(data)\n",
    "\n",
    "greedy_pred_list = []\n",
    "for i in range(len(test_data)):\n",
    "    #print(test_data[i]['sentence'])\n",
    "    greedy_pred_list.append(greedy(test_data[i]['sentence']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedyl = []\n",
    "\n",
    "for i in range(len(greedy_pred_list)):\n",
    "    greedydict = {}\n",
    "    greedydict[\"index\"] = i\n",
    "    greedydict[\"sentence\"] = test_data[i]['sentence'] \n",
    "    greedydict[\"labels\"] = greedy_pred_list[i]\n",
    "    greedyl.append(greedydict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {}\n",
    "z['index'] = 1\n",
    "z['sentence'] = ['a', 'b', 'c']\n",
    "z['label'] = ['x','y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 1, 'sentence': ['a', 'b', 'c'], 'label': ['x', 'y', 'z']}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztest = []\n",
    "ztest.append(z)\n",
    "ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(greedyl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(greedy_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedyjson = json.dumps(greedyl, indent=2)\n",
    "with open('output/greedy.json','w') as op:\n",
    "    op.write(greedyjson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
